---
layout: default
title: Program
---

# Program 

Date: 16th September 2019.




<h2>Workshop Program</h2>

<table>
  <tr>
    <th>Time</th>
    <th>Session</th>
    <th>Speaker</th>
    <th>Title</th>
  </tr>
  <tr>
    <th rowspan="4">1100 - 1230<br>(25-min sessions)</th>
    <th rowspan="4">Intro + Big Picture</th>
    <td>Welcome (5-min) - Tony Nowatzki (UCLA) <br>Intro (10-min) - Matt Horsnell (Arm) </td>
  </tr>
  <tr>
    <td>Sarita Adve (UIUC)</td>
    <td> </td>
  </tr>
  <tr>
    <td>Vikram Adve (UIUC)</td>
    <td>HPVM: A Uniform Interface and Abstraction for Heterogeneous Parallel Systems
     </td>
  </tr>
  <tr>
    <td>Arrvindh Shriraman (SFU)</td>
  <td> </td>
  </tr>
  <tr>
    <th>1230 - 1400</th>
    <th colspan="2">Lunch Break</th>
  </tr>
  <tr>
    <th rowspan="4">1400 - 1530<br>(22-min sessions)</th>
    <th rowspan="4">DSLs, Compilers, & IRs</th>
    <td>Thierry Moreau (UoWashington)</td>
    <td>The Past, Present and Future of Deep Learning Acceleration Stacks.
 </td>
  </tr>
  <tr>
    <td>Riyadh Baghdadi (MIT)</td>
    <td>A Polyhedral Compiler for Dense and Sparse Deep Learning and More
 </td>
  </tr>
  <tr>
    <td>Jeff Setter (Stanford)</td>
    <td> </td>
  </tr>
  <tr>
    <td>Naums Mogers (UoEdinburgh)</td>
    <td>Functional Interface for Performance Portability on Parallel Accelerators
 </td>
  </tr>
  <tr>
    <th>1530 - 1600</th>
    <th colspan="2">Break</th>
  </tr>
  <tr>
    <th rowspan="2">1600 - 1650<br>(25-min sessions)</th>
    <th rowspan="2">Programmable Accelerators</th>
    <td>Aviral Shrivastava (ASU)</td>
    <td> dMazeRunner: Accelerate perfectly nested loops on dataflow accelerators
/td>
  </tr>
  <tr>
    <td>Ramana Radhakrishnan (Arm)</td>
    <td> </td>
  </tr>
  <tr>
    <th>1650 - 1730</th>
    <td> Sarita Adve, Vikram Adve, Arrvindh Shriraman, Riyadh Baghdadi </td>
    <td colspan="2" align="center">Panel<br>Moderator - David Weaver (Arm)</td>
  </tr>
</table>




[back](./)
